{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c0c79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Récapitulatif création objets GTFS ----\n",
      "Répertoire GTFS analysé : C:\\Users\\tiend\\Downloads\\Toulouse_GTFS\n",
      "Nombre de stops lus dans stops.txt          : 5569   # Tous les arrêts déclarés dans stops.txt\n",
      "Nombre de stops créés (stopsMap)            : 3759   # Arrêts utilisés (présents aussi dans stop_times.txt)\n",
      "Nombre de trips créés (tripsMap)            : 38719   # trip_id uniques dans trips.txt\n",
      "Nombre de shapes lus dans shapes.txt        : 270853   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\n",
      "Nombre de shapes créés (shapesMap)          : 453   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Les tests pour les modeles de création d'objets Java (Hanoi, Toulouse, Nantes) testCreationObjetsJavaHanoi.gaml\n",
    "import os\n",
    "import csv\n",
    "\n",
    "gtfs_dir = r\"C:\\Users\\tiend\\Downloads\\Toulouse_GTFS\"  # Chemin vers le répertoire GTFS\n",
    "\n",
    "def detect_separator(file_path):\n",
    "    \"\"\"Détecte le séparateur CSV (comme dans le code Java).\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return ','\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        if not first_line:\n",
    "            return ','\n",
    "        \n",
    "        # Compte virgules/points-virgules hors guillemets (logique Java)\n",
    "        comma_count = 0\n",
    "        semicolon_count = 0\n",
    "        in_quotes = False\n",
    "        \n",
    "        for c in first_line:\n",
    "            if c == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "            if not in_quotes:\n",
    "                if c == ',':\n",
    "                    comma_count += 1\n",
    "                elif c == ';':\n",
    "                    semicolon_count += 1\n",
    "        \n",
    "        return ';' if semicolon_count > comma_count else ','\n",
    "\n",
    "def count_lines_without_header(file_path):\n",
    "    \"\"\"Compte les lignes hors header dans un fichier texte.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) <= 1:  # Seulement header ou fichier vide\n",
    "                return 0\n",
    "            return len([line for line in lines[1:] if line.strip()])  # Ignore les lignes vides\n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def get_unique_ids(file_path, id_column):\n",
    "    \"\"\"Retourne l'ensemble des IDs uniques dans une colonne.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(file_path)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            if id_column not in reader.fieldnames:\n",
    "                return set()\n",
    "            return set(row[id_column].strip().replace('\"', '').replace(\"'\", '') \n",
    "                      for row in reader if row[id_column].strip())\n",
    "    except:\n",
    "        return set()\n",
    "\n",
    "def count_shapes_created_java_style():\n",
    "    \"\"\"Simule la logique Java pour compter les shapes créés.\"\"\"\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    \n",
    "    if not os.path.exists(shapes_txt):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(shapes_txt)\n",
    "        valid_shapes = set()\n",
    "        total_lines = 0\n",
    "        error_lines = 0\n",
    "        \n",
    "        with open(shapes_txt, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            \n",
    "            # Vérification des colonnes requises\n",
    "            required_cols = ['shape_id', 'shape_pt_lat', 'shape_pt_lon']\n",
    "            if not all(col in reader.fieldnames for col in required_cols):\n",
    "                return \"Colonnes manquantes\"\n",
    "            \n",
    "            for row in reader:\n",
    "                total_lines += 1\n",
    "                try:\n",
    "                    # Simulation exacte de la logique Java\n",
    "                    shape_id = int(row['shape_id'].strip())  # Integer.parseInt()\n",
    "                    lat = float(row['shape_pt_lat'].strip())  # Double.parseDouble()\n",
    "                    lon = float(row['shape_pt_lon'].strip())  # Double.parseDouble()\n",
    "                    \n",
    "                    # Si on arrive ici, la ligne est valide (comme en Java)\n",
    "                    valid_shapes.add(shape_id)\n",
    "                    \n",
    "                except (ValueError, KeyError):\n",
    "                    # Équivalent du catch Exception en Java\n",
    "                    error_lines += 1\n",
    "                    continue\n",
    "        \n",
    "        return len(valid_shapes)\n",
    "    \n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def analyze_gtfs():\n",
    "    \"\"\"Analyse complète GTFS avec les mêmes indicateurs que le code Java.\"\"\"\n",
    "    \n",
    "    print(\"---- Récapitulatif création objets GTFS ----\")\n",
    "    print(f\"Répertoire GTFS analysé : {gtfs_dir}\")\n",
    "    \n",
    "    # 1. Nombre de stops lus dans stops.txt\n",
    "    stops_txt = os.path.join(gtfs_dir, \"stops.txt\")\n",
    "    stops_lus = count_lines_without_header(stops_txt)\n",
    "    print(f\"Nombre de stops lus dans stops.txt          : {stops_lus}   # Tous les arrêts déclarés dans stops.txt\")\n",
    "    \n",
    "    # 2. Nombre de stops créés (présents dans stops.txt ET utilisés dans stop_times.txt)\n",
    "    if stops_lus != \"Absent\":\n",
    "        stops_declared = get_unique_ids(stops_txt, \"stop_id\")\n",
    "        stops_used = get_unique_ids(os.path.join(gtfs_dir, \"stop_times.txt\"), \"stop_id\")\n",
    "        stops_crees = len(stops_declared & stops_used) if stops_declared and stops_used else 0\n",
    "    else:\n",
    "        stops_crees = \"Absent\"\n",
    "    print(f\"Nombre de stops créés (stopsMap)            : {stops_crees}   # Arrêts utilisés (présents aussi dans stop_times.txt)\")\n",
    "    \n",
    "    # 3. Nombre de trips créés\n",
    "    trips_txt = os.path.join(gtfs_dir, \"trips.txt\")\n",
    "    if os.path.exists(trips_txt):\n",
    "        trips_ids = get_unique_ids(trips_txt, \"trip_id\")\n",
    "        trips_crees = len(trips_ids)\n",
    "    else:\n",
    "        trips_crees = \"Absent\"\n",
    "    print(f\"Nombre de trips créés (tripsMap)            : {trips_crees}   # trip_id uniques dans trips.txt\")\n",
    "    \n",
    "    # 4. Nombre de shapes lus dans shapes.txt\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    shapes_lus = count_lines_without_header(shapes_txt)\n",
    "    print(f\"Nombre de shapes lus dans shapes.txt        : {shapes_lus}   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\")\n",
    "    \n",
    "    # 5. Nombre de shapes créés (avec logique Java)\n",
    "    shapes_crees = count_shapes_created_java_style()\n",
    "    print(f\"Nombre de shapes créés (shapesMap)          : {shapes_crees}   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\")\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_gtfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6c3376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Récapitulatif création objets GTFS ----\n",
      "Répertoire GTFS analysé : C:\\Users\\tiend\\Downloads\\GTFS_Hanoi\n",
      "Nombre de stops lus dans stops.txt          : 7670   # Tous les arrêts déclarés dans stops.txt\n",
      "Nombre de stops créés (stopsMap)            : 7670   # Arrêts utilisés (présents aussi dans stop_times.txt)\n",
      "Nombre de trips créés (tripsMap)            : 6713   # trip_id uniques dans trips.txt\n",
      "Nombre de shapes lus dans shapes.txt        : Absent   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\n",
      "Nombre de shapes créés (shapesMap)          : Absent   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Les tests pour les modeles de création d'objets Java (Hanoi, Toulouse, Nantes) testCreationObjetsJavaHanoi.gaml\n",
    "import os\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "gtfs_dir = r\"C:\\Users\\tiend\\Downloads\\GTFS_Hanoi\"  # Chemin vers le répertoire GTFS\n",
    "\n",
    "def detect_separator(file_path):\n",
    "    \"\"\"Détecte le séparateur CSV (comme dans le code Java).\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return ','\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        if not first_line:\n",
    "            return ','\n",
    "        \n",
    "        # Compte virgules/points-virgules hors guillemets (logique Java)\n",
    "        comma_count = 0\n",
    "        semicolon_count = 0\n",
    "        in_quotes = False\n",
    "        \n",
    "        for c in first_line:\n",
    "            if c == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "            if not in_quotes:\n",
    "                if c == ',':\n",
    "                    comma_count += 1\n",
    "                elif c == ';':\n",
    "                    semicolon_count += 1\n",
    "        \n",
    "        return ';' if semicolon_count > comma_count else ','\n",
    "\n",
    "def count_lines_without_header(file_path):\n",
    "    \"\"\"Compte les lignes hors header dans un fichier texte.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) <= 1:  # Seulement header ou fichier vide\n",
    "                return 0\n",
    "            return len([line for line in lines[1:] if line.strip()])  # Ignore les lignes vides\n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def get_unique_ids(file_path, id_column):\n",
    "    \"\"\"Retourne l'ensemble des IDs uniques dans une colonne.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(file_path)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            if id_column not in reader.fieldnames:\n",
    "                return set()\n",
    "            return set(row[id_column].strip().replace('\"', '').replace(\"'\", '') \n",
    "                      for row in reader if row[id_column].strip())\n",
    "    except:\n",
    "        return set()\n",
    "\n",
    "def count_shapes_created_java_style():\n",
    "    \"\"\"Simule la logique Java pour compter les shapes créés.\"\"\"\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    \n",
    "    if not os.path.exists(shapes_txt):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(shapes_txt)\n",
    "        valid_shapes = set()\n",
    "        total_lines = 0\n",
    "        error_lines = 0\n",
    "        \n",
    "        with open(shapes_txt, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            \n",
    "            # Vérification des colonnes requises\n",
    "            required_cols = ['shape_id', 'shape_pt_lat', 'shape_pt_lon']\n",
    "            if not all(col in reader.fieldnames for col in required_cols):\n",
    "                return \"Colonnes manquantes\"\n",
    "            \n",
    "            for row in reader:\n",
    "                total_lines += 1\n",
    "                try:\n",
    "                    # Simulation exacte de la logique Java\n",
    "                    shape_id = int(row['shape_id'].strip())  # Integer.parseInt()\n",
    "                    lat = float(row['shape_pt_lat'].strip())  # Double.parseDouble()\n",
    "                    lon = float(row['shape_pt_lon'].strip())  # Double.parseDouble()\n",
    "                    \n",
    "                    # Si on arrive ici, la ligne est valide (comme en Java)\n",
    "                    valid_shapes.add(shape_id)\n",
    "                    \n",
    "                except (ValueError, KeyError):\n",
    "                    # Équivalent du catch Exception en Java\n",
    "                    error_lines += 1\n",
    "                    continue\n",
    "        \n",
    "        return len(valid_shapes)\n",
    "    \n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def analyze_gtfs():\n",
    "    \"\"\"Analyse complète GTFS avec les mêmes indicateurs que le code Java.\"\"\"\n",
    "    \n",
    "    print(\"---- Récapitulatif création objets GTFS ----\")\n",
    "    print(f\"Répertoire GTFS analysé : {gtfs_dir}\")\n",
    "    \n",
    "    # 1. Nombre de stops lus dans stops.txt\n",
    "    stops_txt = os.path.join(gtfs_dir, \"stops.txt\")\n",
    "    stops_lus = count_lines_without_header(stops_txt)\n",
    "    print(f\"Nombre de stops lus dans stops.txt          : {stops_lus}   # Tous les arrêts déclarés dans stops.txt\")\n",
    "    \n",
    "    # 2. Nombre de stops créés (présents dans stops.txt ET utilisés dans stop_times.txt)\n",
    "    if stops_lus != \"Absent\":\n",
    "        stops_declared = get_unique_ids(stops_txt, \"stop_id\")\n",
    "        stops_used = get_unique_ids(os.path.join(gtfs_dir, \"stop_times.txt\"), \"stop_id\")\n",
    "        stops_crees = len(stops_declared & stops_used) if stops_declared and stops_used else 0\n",
    "    else:\n",
    "        stops_crees = \"Absent\"\n",
    "    print(f\"Nombre de stops créés (stopsMap)            : {stops_crees}   # Arrêts utilisés (présents aussi dans stop_times.txt)\")\n",
    "    \n",
    "    # 3. Nombre de trips créés\n",
    "    trips_txt = os.path.join(gtfs_dir, \"trips.txt\")\n",
    "    if os.path.exists(trips_txt):\n",
    "        trips_ids = get_unique_ids(trips_txt, \"trip_id\")\n",
    "        trips_crees = len(trips_ids)\n",
    "    else:\n",
    "        trips_crees = \"Absent\"\n",
    "    print(f\"Nombre de trips créés (tripsMap)            : {trips_crees}   # trip_id uniques dans trips.txt\")\n",
    "    \n",
    "    # 4. Nombre de shapes lus dans shapes.txt\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    shapes_lus = count_lines_without_header(shapes_txt)\n",
    "    print(f\"Nombre de shapes lus dans shapes.txt        : {shapes_lus}   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\")\n",
    "    \n",
    "    # 5. Nombre de shapes créés (avec logique Java)\n",
    "    shapes_crees = count_shapes_created_java_style()\n",
    "    print(f\"Nombre de shapes créés (shapesMap)          : {shapes_crees}   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\")\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_gtfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0836561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Récapitulatif création objets GTFS ----\n",
      "Répertoire GTFS analysé : C:\\Users\\tiend\\Downloads\\gtfs-tan\n",
      "Nombre de stops lus dans stops.txt          : 3687   # Tous les arrêts déclarés dans stops.txt\n",
      "Nombre de stops créés (stopsMap)            : 2556   # Arrêts utilisés (présents aussi dans stop_times.txt)\n",
      "Nombre de trips créés (tripsMap)            : 30548   # trip_id uniques dans trips.txt\n",
      "Nombre de shapes lus dans shapes.txt        : 14608   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\n",
      "Nombre de shapes créés (shapesMap)          : 261   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "gtfs_dir = r\"C:\\Users\\tiend\\Downloads\\gtfs-tan\"  # Chemin vers le répertoire GTFS\n",
    "\n",
    "def detect_separator(file_path):\n",
    "    \"\"\"Détecte le séparateur CSV (comme dans le code Java).\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return ','\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        if not first_line:\n",
    "            return ','\n",
    "        \n",
    "        # Compte virgules/points-virgules hors guillemets (logique Java)\n",
    "        comma_count = 0\n",
    "        semicolon_count = 0\n",
    "        in_quotes = False\n",
    "        \n",
    "        for c in first_line:\n",
    "            if c == '\"':\n",
    "                in_quotes = not in_quotes\n",
    "            if not in_quotes:\n",
    "                if c == ',':\n",
    "                    comma_count += 1\n",
    "                elif c == ';':\n",
    "                    semicolon_count += 1\n",
    "        \n",
    "        return ';' if semicolon_count > comma_count else ','\n",
    "\n",
    "def count_lines_without_header(file_path):\n",
    "    \"\"\"Compte les lignes hors header dans un fichier texte.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) <= 1:  # Seulement header ou fichier vide\n",
    "                return 0\n",
    "            return len([line for line in lines[1:] if line.strip()])  # Ignore les lignes vides\n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def get_unique_ids(file_path, id_column):\n",
    "    \"\"\"Retourne l'ensemble des IDs uniques dans une colonne.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(file_path)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            if id_column not in reader.fieldnames:\n",
    "                return set()\n",
    "            return set(row[id_column].strip().replace('\"', '').replace(\"'\", '') \n",
    "                      for row in reader if row[id_column].strip())\n",
    "    except:\n",
    "        return set()\n",
    "\n",
    "def count_shapes_created_java_style():\n",
    "    \"\"\"Simule la logique Java pour compter les shapes créés.\"\"\"\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    \n",
    "    if not os.path.exists(shapes_txt):\n",
    "        return \"Absent\"\n",
    "    \n",
    "    try:\n",
    "        separator = detect_separator(shapes_txt)\n",
    "        valid_shapes = set()\n",
    "        total_lines = 0\n",
    "        error_lines = 0\n",
    "        \n",
    "        with open(shapes_txt, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=separator)\n",
    "            \n",
    "            # Vérification des colonnes requises\n",
    "            required_cols = ['shape_id', 'shape_pt_lat', 'shape_pt_lon']\n",
    "            if not all(col in reader.fieldnames for col in required_cols):\n",
    "                return \"Colonnes manquantes\"\n",
    "            \n",
    "            for row in reader:\n",
    "                total_lines += 1\n",
    "                try:\n",
    "                    # Simulation exacte de la logique Java\n",
    "                    shape_id = int(row['shape_id'].strip())  # Integer.parseInt()\n",
    "                    lat = float(row['shape_pt_lat'].strip())  # Double.parseDouble()\n",
    "                    lon = float(row['shape_pt_lon'].strip())  # Double.parseDouble()\n",
    "                    \n",
    "                    # Si on arrive ici, la ligne est valide (comme en Java)\n",
    "                    valid_shapes.add(shape_id)\n",
    "                    \n",
    "                except (ValueError, KeyError):\n",
    "                    # Équivalent du catch Exception en Java\n",
    "                    error_lines += 1\n",
    "                    continue\n",
    "        \n",
    "        return len(valid_shapes)\n",
    "    \n",
    "    except:\n",
    "        return \"Erreur\"\n",
    "\n",
    "def analyze_gtfs():\n",
    "    \"\"\"Analyse complète GTFS avec les mêmes indicateurs que le code Java.\"\"\"\n",
    "    \n",
    "    print(\"---- Récapitulatif création objets GTFS ----\")\n",
    "    print(f\"Répertoire GTFS analysé : {gtfs_dir}\")\n",
    "    \n",
    "    # 1. Nombre de stops lus dans stops.txt\n",
    "    stops_txt = os.path.join(gtfs_dir, \"stops.txt\")\n",
    "    stops_lus = count_lines_without_header(stops_txt)\n",
    "    print(f\"Nombre de stops lus dans stops.txt          : {stops_lus}   # Tous les arrêts déclarés dans stops.txt\")\n",
    "    \n",
    "    # 2. Nombre de stops créés (présents dans stops.txt ET utilisés dans stop_times.txt)\n",
    "    if stops_lus != \"Absent\":\n",
    "        stops_declared = get_unique_ids(stops_txt, \"stop_id\")\n",
    "        stops_used = get_unique_ids(os.path.join(gtfs_dir, \"stop_times.txt\"), \"stop_id\")\n",
    "        stops_crees = len(stops_declared & stops_used) if stops_declared and stops_used else 0\n",
    "    else:\n",
    "        stops_crees = \"Absent\"\n",
    "    print(f\"Nombre de stops créés (stopsMap)            : {stops_crees}   # Arrêts utilisés (présents aussi dans stop_times.txt)\")\n",
    "    \n",
    "    # 3. Nombre de trips créés\n",
    "    trips_txt = os.path.join(gtfs_dir, \"trips.txt\")\n",
    "    if os.path.exists(trips_txt):\n",
    "        trips_ids = get_unique_ids(trips_txt, \"trip_id\")\n",
    "        trips_crees = len(trips_ids)\n",
    "    else:\n",
    "        trips_crees = \"Absent\"\n",
    "    print(f\"Nombre de trips créés (tripsMap)            : {trips_crees}   # trip_id uniques dans trips.txt\")\n",
    "    \n",
    "    # 4. Nombre de shapes lus dans shapes.txt\n",
    "    shapes_txt = os.path.join(gtfs_dir, \"shapes.txt\")\n",
    "    shapes_lus = count_lines_without_header(shapes_txt)\n",
    "    print(f\"Nombre de shapes lus dans shapes.txt        : {shapes_lus}   # Nombre de lignes - header dans shapes.txt ('Absent' si non présent)\")\n",
    "    \n",
    "    # 5. Nombre de shapes créés (avec logique Java)\n",
    "    shapes_crees = count_shapes_created_java_style()\n",
    "    print(f\"Nombre de shapes créés (shapesMap)          : {shapes_crees}   # Nombre de shape_id uniques (shapes uniques, 'Absent' si shapes.txt absent)\")\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_gtfs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
